{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "from ND_north_star.src.utils.data_to_xarray import create_perlin_dataset, xarray_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 80\n",
    "octave = 3\n",
    "dimensions = [resolution, resolution]\n",
    "boundary_points = 500\n",
    "\n",
    "images = 50\n",
    "\n",
    "combined_ds = create_perlin_dataset(images, dimensions=dimensions, octave=octave, random_num_samples=1000, boundary_points=boundary_points)"
=======
    "from ND_north_star.src.utils.data_to_dict import create_perlin_dict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
>>>>>>> 9c792048e25ede37b67affed6feb79c2dc2921a9
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping boundary -1: Not enough points to fit a spline.\n",
      "Skipping boundary -1: Not enough points to fit a spline.\n",
      "Skipping boundary -1: Not enough points to fit a spline.\n",
      "Skipping boundary 1: Not enough points to fit a spline.\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "resolution = 80\n",
    "octave_list = [2,3,4,5]\n",
    "dimensions = [resolution, resolution]\n",
    "\n",
    "boundary_points = 500\n",
    "images = 3\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for octave in octave_list:\n",
    "    data_dict_list = create_perlin_dict_dataset(images, dimensions=dimensions, octave=octave, random_num_samples=1000, boundary_points=boundary_points)\n",
    "    all_images.extend(data_dict_list)\n",
    "\n",
    "for image_ind, image_dict in enumerate(all_images):\n",
    "    image_dict['index'] = image_ind\n",
    "\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['features', 'values', 'octaves', 'resolution', 'features_sampled', 'values_sampled', 'boundary_splines', 'index'])\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "save_dict = all_images[7]\n",
    "print(save_dict.keys())\n",
    "# print(save_dict)\n",
    "\n",
    "# for save_dict in all_images:\n",
    "#     print(save_dict['octaves'])\n",
    "\n",
    "#     X0, X1, V = np.array(save_dict['features'])[:, 0], np.array(save_dict['features'])[:, 1], save_dict['values']\n",
    "#     boundary_points = save_dict['boundary_splines']\n",
    "\n",
    "#     plt.scatter(boundary_points[:, 0], boundary_points[:, 1], c='red', s=1)\n",
    "#     plt.scatter(X0, X1, c=V, s=7, cmap='gray_r', edgecolors='black')\n",
    "#     plt.show()\n",
    "\n",
    "#     X0, X1, V = np.array(save_dict['features_sampled'])[:, 0], np.array(save_dict['features_sampled'])[:, 1], save_dict['values_sampled']\n",
    "#     plt.scatter(boundary_points[:, 0], boundary_points[:, 1], c='red', s=1)\n",
    "#     plt.scatter(X0, X1, c=V, s=10, cmap='gray_r', edgecolors='black')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to X,Y tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare input and output lists\n",
    "inputs_list = []\n",
    "targets_list = []\n",
    "\n",
    "for image_dict in all_images:\n",
    "    X0 = torch.tensor(image_dict['features_sampled'][:, 0], dtype=torch.float32)\n",
    "    X1 = torch.tensor(image_dict['features_sampled'][:, 1], dtype=torch.float32)\n",
    "    V = torch.tensor(image_dict['values_sampled'], dtype=torch.float32)\n",
    "\n",
    "    X = torch.stack([X0, X1, V], dim=1).contiguous()  # Ensure contiguous memory\n",
    "    inputs_list.append(X)\n",
    "\n",
    "    X0_boundary = torch.tensor(image_dict['boundary_splines'][:, 0], dtype=torch.float32)\n",
    "    X1_boundary = torch.tensor(image_dict['boundary_splines'][:, 1], dtype=torch.float32)\n",
    "    Y = torch.stack([X0_boundary, X1_boundary], dim=1).contiguous()  # Ensure contiguous memory\n",
    "    targets_list.append(Y)\n",
    "\n",
    "# Convert lists to tensors\n",
    "inputs = torch.stack(inputs_list).contiguous()  # Shape: (num_samples, 1000, 3)\n",
    "targets = torch.stack(targets_list).contiguous()  # Shape: (num_samples, 500, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.inputs[idx].to_sparse()\n",
    "        target_data = self.targets[idx].to_sparse()\n",
    "        return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test_split(inputs, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_inputs, train_targets)\n",
    "test_dataset = CustomDataset(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "def sparse_collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    \n",
    "    # Stack sparse tensors\n",
    "    batched_inputs = torch.stack(inputs).contiguous()  # Ensure contiguous memory\n",
    "    batched_targets = torch.stack(targets).contiguous()  # Ensure contiguous memory\n",
    "    \n",
    "    return batched_inputs, batched_targets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=sparse_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=sparse_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup sparse-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 1000, 512)  # Adjust the size based on your data\n",
    "        self.fc2 = nn.Linear(512, 500 * 2)  # Final layer to produce output of length 500 * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to_dense().float()  # Convert sparse tensor to dense and ensure float32 type\n",
    "        x = x.permute(0, 2, 1).contiguous()  # Change shape to (batch_size, channels, length) and ensure contiguous memory\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1).contiguous()  # Flatten for the fully connected layers and ensure contiguous memory\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 500, 2).contiguous()  # Reshape to the desired output size and ensure contiguous memory\n",
    "        return x\n",
    "\n",
    "model = SparseCNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unsupported memory format option Contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# Number of epochs\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joesc\\anaconda3\\envs\\ND_north_star\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\joesc\\anaconda3\\envs\\ND_north_star\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\joesc\\anaconda3\\envs\\ND_north_star\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36msparse_collate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Stack sparse tensors\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m batched_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure contiguous memory\u001b[39;00m\n\u001b[0;32m      7\u001b[0m batched_targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(targets)\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m# Ensure contiguous memory\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batched_inputs, batched_targets\n",
      "\u001b[1;31mRuntimeError\u001b[0m: unsupported memory format option Contiguous"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.to_dense().float())  # Ensure float32 type\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/10], Step [{i + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for inputs, targets in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.to_dense().float())  # Ensure float32 type\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
